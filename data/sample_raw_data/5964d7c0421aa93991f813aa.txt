Google has launched the People+AI Research initiative (PAIR) with the goal of bringing researchers across Google together to study and redesign the ways people interact with AI systems.

Google announced the initiative yesterday in a blog post, stating that the aim of the project is to focus on the "human side" of AI. This includes the relationship between users and technology, the new applications it enables, and how to make it broadly inclusive.

To study and redesign the ways people interact with AI, we're introducing PAIR%u2014the People + AI Research Initiative. https://t.co/Kc8B84RzLE — Google (@Google) 10 de julio de 2017

It also announced its using open source tools for researchers and other experts to use.

The research is divided into three areas, based on different user needs. The first is for engineers and researchers, as Google wants to make it easier for them to build and understand machine learning systems by providing them with educational materials and practical tools.

The second is for "domain experts", as Google wants to find out how AI can help professionals, such as doctors, musicians and farmers, in their work and support them to increasingly use AI.

The last research area is for everyday users, where Google wants to ensure machine learning is inclusive so everyone can benefit from AI breakthroughs. It also wants to find out if it can democratise the technology behind AI.

Google are open sourcing two visualisation tools: Facets Overview and Facets Dive. It hopes AI engineers will use the tools to give them a clear view of the data they use to train AI systems.

07/04/2017: Adobe demos machine learning selfie editor

Adobe has revealed a sneak peek at the future of selfies, with artificial intelligence tools applied to photo editing making your portrait look like it was taken by a much better camera.

In a YouTube video, Adobe Research showed a series of edits on a selfie image, automatically selecting the subject and shifting the perspective slightly so it "appears to be taken from a distance more typical of a portrait shot", or blurring the background via depth of field. It also showed selecting a photo style to drag and drop onto your own image for a quick edit.

"What if we could tap into the power of artificial intelligence and machine learning to transform bad portraits into good ones," the demo video asks.

The system uses Adobe Sensei, which the software developer describes as "the magic" behind its automated tools, from web and publishing to photo editing. Unveiled last year, Sensei is Adobe's framework for delivering AI and machine learning to its range of products.

In Premiere Pro, Adobe's video editing software, Sensei technologies are used to support a tool called Morph Cut, which analyses the content of video to decide the best type of style to apply – is it an action scene or dramatic closeup? – with the editing effect automatically suggested.

Adobe hasn't said when – or even if – it will release the smart selfie tool, but said it was a peek at the "future of mobile portrait photography".

07/04/2017: IT spending on AI technologies will be worth $12.5bn in 2017

Research by IDC has revealed businesses will spend $12.5 billion (£10.02 billion) on AI technologies by the end of 2017, with the majority of budgets being spent on software and services. By 2020, this will increase to $46 billion (£36.86 billion), the company said, representing an increase of 268% over the three year period.

Cognitive applications will make up the majority of spending topping $4.5 billion (£3.6 billion) by the end of the year, closely followed by services that integrate organising, accessing and analysing data, which will account for $2.5 billion (£2 billion) of spending.

Spending on cognitive-related IT and business services will increase to more than $3.5 billion (£2.81 billion), while dedicated server and storage infrastructure to support these new services will account for $1.9 billion (£1.52 billion) of spending.

“Software developers and end user organisations have already begun the process of embedding and deploying cognitive/artificial intelligence into almost every kind of enterprise application or process,” said David Schubmehl, research director, Cognitive Systems and Content Analytics at IDC.

“Recent announcements by several large technology vendors and the booming venture capital market for AI startups illustrate the need for organisations to be planning and undertaking strategies that incorporate these wide-ranging technologies."

Heavily regulated markets such as banking and securities are driving AI adoption in business, accounting for more than a quarter of total spending. AI offers the insights businesses in highly compliant sectors need to keep on top of fraud and risk detection, IDC explained.

"Identifying, understanding, and acting on the use cases, technologies, and growth opportunities for cognitive/AI systems will be a differentiating factor for most enterprises and the digital disruption caused by these technologies will be significant,” Schubmehl added.

10/03/2017: Machines set to take over human intelligence by 2027

Research by Pearson and Professor Brendan O’Connor from the University of Massachusetts Amherst has revealed that AI-powered services such as Cortana, and Siri will be better at reading and writing than one in twenty British adults over the next ten years.

According to the report's findings, which was developed in response to Pearson's new Project Literacy initiative, 1% of Brits are unable to read or write at present and although machines aren't intelligent enough to overtake that group of people yet, the rate speech and language processing is evolving will expose a huge gap in adult learning.

“Our new report highlights the gulf between technological and human progression," said Kate James, Project Literacy spokeswoman.

"It is predicted that more than two billion smartphones will soon be capable of reading and writing, but 758 million people in the world still lack basic literacy skills and this skills gap is being passed on from generation to generation. It doesn’t have to be a zero-sum game – technology has a crucial role to play in the fight against illiteracy."

The research has revealed a number of shocking statistics, including that in the UK's most deprived areas, more than a third of adults lack the literacy of an 11-year old. In fact, the UK is one of the only countries in the developed world where adults aged between 55 and 65 perform better in literacy tests than 16-24 year olds.

In the US, there are more software engineers than school teachers, which Project Literacy argues means more focus is being put on developing the intelligence of machines than humans.

“‘Machine reading’ is not close to mastering the full nuances of human language and intelligence, despite this idea capturing the imagination of popular culture in movies such as ‘Her’," professor Brendan O’Connor of the University of Massachusetts Amherst, said.

"However advances in technology mean that it is likely ‘machines’ will achieve literacy abilities exceeding those of 1 in 20 British people within the next decade."

27/02/2017: Artifical intelligence will receive funding under government's digital strategy

The government has released details of its digital strategy, with AI receiving a substantial amount of funding to help the UK's artificial intelligence research become a bigger part of the country's economy.

Although the UK has a lot of talent in the AI arena, there's space for further growth, the government explained. To push this forward, the it will launch an AI review, led by Wendy Hall, regius professor of computer science at the University of Southampton and Jérôme Pesenti, the CEO of BenevolentTech, to identify how the UK can make its mark in the world of AI.

The government will also contribute £17.3 million of funding to the sector via the Engineering and Physical Sciences Research Council (EPSRC), which will encourage the development of AI and robotics projects at universities around the UK.

“Britain has a proud history of digital innovation - from the earliest days of computing to Sir Tim Berners-Lee’s development of the World Wide Web," culture secretary Karen Bradley said. “We are already pioneers in today’s artificial intelligence revolution and the Digital Strategy will build on our strengths to make sure UK-based scientists, researchers and entrepreneurs continue to be at the forefront."

Bradley will launch the government's digital strategy on Wednesday, 1 March, detailing other initiatives that will enable the UK to flourish in the areas of cyber security, connected and smart devices, and autonomous vehicles too.

“Investment in robotics and artificial intelligence will help make our economy more competitive, build on our world-leading reputation in these cutting-edge sectors and help us create new products, develop more innovative services and establish better ways of doing business," business secretary Greg Clark said.

“Innovation is at the heart of our Industrial Strategy and the launch of the Government’s Digital Strategy underlines our commitment to this vital sector. By supporting British businesses and investing in dynamic fields such as robotics and AI, we will help put the UK at the forefront of global innovation.”

23/02/2017: DeepCoder AI can write its own code

Researchers at Microsoft and Cambridge University have created an AI system capable of solving programming problems by adapting code from other existing software.

The machine learning system, known as "DeepCoder", is essentially able to write its own code, and has been successful at deciphering the kind of problems faced by those entering programming competitions.

Researchers believe DeepCoder will make it easier for people to build basic programs without the need for coding skills. Non-coders may simply just need to describe an idea, and let the AI develop it for them.

"We have found several problems in real online programming challenges that can be solved with a program in our language," said the researchers in a paper of their findings. "We are able to solve problems of difficulty comparable to the simplest problems on programming competition websites."

DeepCoder works by using 'program synthesis', the process of categorising various inputs and outputs of different pieces of code, learning what each line does and clumping them together to create a program that is able to solve the presented problem.

It is able to take pieces of code from existing software, in much the same way a human coder might do, learn what that code does, and adapt it to fit an entirely different purpose.

Unlike a human coder, the AI is able to search a wider range of existing programs more thoroughly, then stitch together code in a way that may not be obvious to a human. Naturally this also makes the whole process a lot faster, as DeepCoder was able to create programs within fractions of a second.

Speaking to the New Scientist, Armando Solar-Lezama, an associate professor whose work was cited in the paper, said: "All of a sudden, people could be so much more productive. The potential for automation that this kind of technology offers could really signify an enormous [reduction] in the amount of effort it takes to develop code."

Right now the system is still only able to solve basic programming challenges involving only a few lines of code, but this could be applied to various use cases, including rapidly responding to new bugs or exploits in existing software.

"Generating a really big piece of code in one shot is hard, and potentially unrealistic," says Solar-Lezama. "But really big pieces of code are built by putting together lots of little pieces of code."

Picture: Bigstock

AI at a glance

AI is a subset of computer science where the goal is to create a computer that is capable of performing tasks normally done by humans acting intelligently.

It is not the attempt to automate the work of a human, nor do we want computers with astoundingly high IQs. Instead it is the process of creating a machine that can learn from its actions and adapt its behaviour with intelligent thinking.

AI comes in various forms and applications, from 'weak' and 'strong', to 'general' and 'applied'. To find out more, head over to our What is AI? hub.